{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_e5ak01BL77T"
   },
   "source": [
    "Dataset: https://grouplens.org/datasets/movielens/1m/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ZaocWZ94MD-e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "import warnings\n",
    "\n",
    "data_df = pd.read_csv('./ratings.dat', sep='::', names=[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"], engine='python')\n",
    "\n",
    "# First, generate dictionaries for mapping old id to new id for users and movies\n",
    "unique_MovieID = data_df['MovieID'].unique()\n",
    "unique_UserID = data_df['UserID'].unique()\n",
    "j = 0\n",
    "user_old2new_id_dict = dict()\n",
    "for u in unique_UserID:\n",
    "    user_old2new_id_dict[u] = j\n",
    "    j += 1\n",
    "j = 0\n",
    "movie_old2new_id_dict = dict()\n",
    "for i in unique_MovieID:\n",
    "    movie_old2new_id_dict[i] = j\n",
    "    j += 1\n",
    "\n",
    "# Then, use the generated dictionaries to reindex UserID and MovieID in the data_df\n",
    "user_list = data_df['UserID'].values\n",
    "movie_list = data_df['MovieID'].values\n",
    "for j in range(len(data_df)):\n",
    "    user_list[j] = user_old2new_id_dict[user_list[j]]\n",
    "    movie_list[j] = movie_old2new_id_dict[movie_list[j]]\n",
    "data_df['UserID'] = user_list\n",
    "data_df['movieID'] = movie_list\n",
    "\n",
    "# generate train_df with 70% samples and test_df with 30% samples, and there should have no overlap between them.\n",
    "train_index = np.random.random(len(data_df)) <= 0.7\n",
    "train_df = data_df[train_index]\n",
    "test_df = data_df[~train_index]\n",
    "\n",
    "# generate train_mat and test_mat\n",
    "num_user = len(data_df['UserID'].unique())\n",
    "num_movie = len(data_df['MovieID'].unique())\n",
    "\n",
    "train_mat = coo_matrix((train_df['Rating'].values, (train_df['UserID'].values, train_df['MovieID'].values)), shape=(num_user, num_movie)).astype(float).toarray()\n",
    "test_mat = coo_matrix((test_df['Rating'].values, (test_df['UserID'].values, test_df['MovieID'].values)), shape=(num_user, num_movie)).astype(float).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xYOhAdIsbj51"
   },
   "outputs": [],
   "source": [
    "# Baseline Estimation Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "nq4mri2zbj51"
   },
   "outputs": [],
   "source": [
    "# calculate the prediction_mat by the baseline estimation recommendation algorithm\n",
    "# Your Code Here...\n",
    "# initialize prediction_mat with zeros\n",
    "prediction_mat = np.zeros((num_user, num_movie))\n",
    "\n",
    "# overall mean rating\n",
    "overall_mean_rating = np.mean(train_mat[train_mat != 0])\n",
    "\n",
    "# mean ratings for users and items\n",
    "user_means = np.zeros(num_user)\n",
    "for user_idx in range(num_user):\n",
    "    user_ratings = train_mat[user_idx, :]\n",
    "    user_ratings = user_ratings[user_ratings != 0]\n",
    "    if len(user_ratings) > 0:\n",
    "        user_means[user_idx] = np.mean(user_ratings) - overall_mean_rating\n",
    "\n",
    "item_means = np.zeros(num_movie)\n",
    "for item_idx in range(num_movie):\n",
    "    item_ratings = train_mat[:, item_idx]\n",
    "    item_ratings = item_ratings[item_ratings != 0]\n",
    "    if len(item_ratings) > 0:\n",
    "        item_means[item_idx] = np.mean(item_ratings) - overall_mean_rating\n",
    "\n",
    "# baseline estimates for each user-movie pair\n",
    "for user_idx in range(num_user):\n",
    "    for movie_idx in range(num_movie):\n",
    "        prediction_mat[user_idx, movie_idx] = overall_mean_rating + user_means[user_idx] + item_means[movie_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error (RMSE) for Baseline Estimate Model: 0.935792164386952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohitsarin/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#import \n",
    "from sklearn.metrics import mean_squared_error\n",
    "# calculate and print out the RMSE for your prediction_df and the test_df\n",
    "# Your Code Here...\n",
    "non_zero_mask = test_mat != 0\n",
    "\n",
    "# Flatten the prediction matrix and test matrix using the non-zero mask\n",
    "prediction_flat = prediction_mat[non_zero_mask]\n",
    "test_flat = test_mat[non_zero_mask]\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = mean_squared_error(test_flat, prediction_flat, squared=False)\n",
    "\n",
    "# Print RMSE\n",
    "print(f\"Root Mean Square Error (RMSE) for Baseline Estimate Model: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Ywt9ohHtL77T",
    "N7x8b4HNbj5z",
    "9Tl2tFlibnAY",
    "wKZ8ijNPTXMN"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
